#!/bin/bash

#
# FIXME ASSUME S3 URL LOOKS LIKE THIS:
#
# base_dir
#       - home
#       - database
#
# It's faster to sync an uncompressed home directory
# database directory should be as created by mysqlsh
#

APP="{{ atl_product_family }}"

s3_backup_url_raw=$1
if test -z "$s3_backup_url_raw"; then
       cat << EOF
Usage: $0 s3_backup_url

Restore database and home directory for app "$APP";
s3_backup_url must contain directories
- home      App home directory 
- backup    Backup as created by mysqlsh

THE APPLICATION SHOULD BE STOPPED BEFORE RESTORE!
EOF
exit 1
fi

# Lop off last char if it's /
s3_backup_url=$(echo $s3_backup_url_raw | sed -e 's/^\(.*\)\/$/\1/')

if systemctl is-active --quiet $APP; then
    echo "Service \"$APP\" is running; must be stopped before restore."
    exit 1
fi

if ! s5cmd ls "${s3_backup_url}/home" > /dev/null 2>&1; then
    echo "s3_backup_url doesn't have home directory"
    exit 1
fi

if ! s5cmd ls "${s3_backup_url}/database" > /dev/null 2>&1; then
    echo "s3_backup_url doesn't have database"
    exit 1
fi

# /var/tmp is bigger
export TEMPDIR=$(mktemp -p /var/tmp -d)

##############################################
# Restore home directory
##############################################
echo "Restoring home directory from clone backup"

# Tar up local retained files
# Filenames are for find command
retained_files="${TEMPDIR}/retained_files_list"
for pattern in $(yq -r '.filesystem.retained[]' /var/clone_config.yaml); do
    find -L {{ atl_product_home }} -type f -wholename "'${pattern}'" >> $retained_files
done
retained_files_tar="${TEMPDIR}/retained_files.tgz"
tar -C / --files-from=$retained_files -czf $retained_files_tar

# sync directory
s5cmd sync --delete "${s3_backup_url}/home/*" "{{ atl_product_home }}/"

# untar retained over sync'd directory
tar -C / -zxf $retained_files_tar
chown -R {{ atl_product_user }}:{{ atl_product_user }} {{ atl_product_home }}

# Delete log files since they're not relevant after clone
find "{{ atl_product_home }}" -wholename '*/logs/*' -delete -o -wholename '*/log/*' -delete

##############################################
# Restore database
##############################################
echo "Restoring database from clone backup"

# Save stuff we need from the database.  We do this by creating dumps
# for these by passing queries to mysqldump
mycnf=$(/usr/local/bin/create_mycnf.sh)
mysql_to_restore="${TEMPDIR}/mysql_to_restore"
mkdir $mysql_to_restore

#
# FIXME break each out into its own file; can have multiple for each table
# how to assure uniqueness of file? mktemp?
#

# Whole tables
full_tables=$(yq -r '.database.retained.tables[]' /var/clone_config.yaml | tr "\n" " ")
for table in $full_tables; do
    mkdir -p "${mysql_to_restore}/${table}" >/dev/null 2>&1
    mysqldump --defaults-file=$mycnf \
	      --add-drop-table \
	      --create-options \
	      --disable-keys \
	      --set-gtid-purged=OFF \
	      {{ atl_jdbc_db_name }} $table > $(mktemp -p "${mysql_to_restore}/${table}")
done

# Queries
queried_tables=$(yq -r '.database.retained.queries | keys[]' /var/clone_config.yaml)
for table in $queried_tables; do
    mkdir -p "${mysql_to_restore}/${table}" >/dev/null 2>&1
    for query in $(yq -r ".database.retained.queries.${table}[]" /var/clone_config.yaml); do
	mysqldump --defaults-file=$mycnf \
		  --disable-keys \
                  --no-create-info \
                  --no-tablespaces \
                  --replace \
                  --set-gtid-purged=OFF \
                  --single-transaction \
                  --skip-triggers \
		  --where="'${query}'" \
		  {{ atl_jdbc_db_name }} $table > $(mktemp -p "${mysql_to_restore}/${table}")
    done
done

# Parse s3_backup_url
bucketname=$(echo $s3_backup_url | cut -d '/' -f3)
prefix="$(echo $s3_backup_url | cut -d '/' -f4-)/database"

# Whatever version of the AWS API that mysqlsh is using, it needs
# credentials in env vars instead of the instance role
aws_env_vars=$(/usr/local/bin/aws_env_credentials_from_instance_role.sh)
source $aws_env_vars
rm $aws_env_vars

# Restore clone database over existing database
/usr/local/bin/drop_all_tables.sh
mysqlsh_cmd="${TEMPDIR}/mysqlsh_cmd"
cat << EOF >$mysqlsh_cmd
util.loadDump(
  "$prefix",
  {
    schema: "{{ atl_jdbc_db_name }}",
    s3BucketName: "$bucketname",
    progressFile: "",
    resetProgress: "true"     
  }
)
EOF
mysqlsh --defaults-file=$mycnf --javascript --file=$mysqlsh_cmd

# Generate list of tables for literal string substitutions
edit_tables="${TEMPDIR}/edit_tables"
for raw_table in $(yq -r ".database.substitutions.tables[]" /var/clone_config.yaml); do
    if echo $raw_table | grep -Fq '%'; then
	mysql --defaults-file=$mycnf --batch -e "show tables like '${table}';" >> $edit_tables
    else
	echo $raw_table >> $edit_tables
    fi
done

src_baseurl="$(/usr/local/bin/get_baseurl.sh)"
src_site="$(echo $src_baseurl | awk -F/ '{print $3}')"
dest_baseurl="{{ atl_base_url }}"
dest_site="$(echo $dest_baseurl | awk -F/ '{print $3}')"

# Dump table, replace strings
for table in $(cat $edit_tables); do
    mkdir -p "${mysql_to_restore}/${table}" >/dev/null 2>&1
    tablesql=$(mktemp -p "${mysql_to_restore}/${table}")
    mysqldump --defaults-file=$mycnf \
	      --disable-keys \
              --no-create-info \
              --no-tablespaces \
              --replace \
              --set-gtid-purged=OFF \
              --single-transaction \
              --skip-triggers \
	      {{ atl_jdbc_db_name }} $table > $tablesql

    # Replace base url, then replace site
    rpl -F "${src_baseurl@Q}" "${dest_baseurl@Q}" $tablesql
    rpl -F "${src_site@Q}" "${dest_site@Q}" $tablesql
    
    for subst_str in $(yq -r ".database.substitutions.strings[]" /var/clone_config.yaml); do
	# https://www.gnu.org/software/bash/manual/html_node/Shell-Parameter-Expansion.html
	subst_val=$(yq -r ".database.substitutions.strings.${subst_str}" /var/clone_config.yaml)
	rpl -F "${subst_str@Q}" "${subst_val@Q}" $tablesql
    done
    
    if ! test -s $tablesql; then
	rm $tablesql
    fi
done

#
# Restore edited and retained data for database
#
# WARNING the order is undetermined, so dumpfile must not step on each
# other's toes
for table in $(ls $mysql_to_restore); do
    for dump in $(ls "${mysql_to_restore}/${table}"); do
	mysql --defaults-file=$mycnf {{ atl_jdbc_db_name }} $table < $dump
    done
done

##############################################
# Postprocess
# Run app-specific post-process script if it exists
##############################################
test -e /usr/local/bin/clone_postprocess && /usr/local/bin/clone_postprocess

rm -rf $TEMPDIR
rm $mycnf

